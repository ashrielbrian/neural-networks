{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briant/opt/anaconda3/envs/torch-cv2/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open(\"names.txt\").read().split(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigram count-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = {}\n",
    "\n",
    "for w in words:\n",
    "    w = \".\" + w + \".\"\n",
    "    for ch in zip(w, w[1:], w[2:]):\n",
    "        trigrams[ch] = trigrams.get(ch, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([27, 27, 27]), torch.float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 for smoothing\n",
    "p = torch.zeros(27, 27, 27) + 1\n",
    "p.shape, p.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted([\".\"] + list(set(\"\".join(words))))\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
       "         [  1., 207., 190.,  ...,  27., 173., 152.],\n",
       "         [  1., 169.,   1.,  ...,   1.,   4.,   1.],\n",
       "         ...,\n",
       "         [  1.,  57.,   1.,  ...,   1.,  17.,  11.],\n",
       "         [  1., 246.,   1.,  ...,   1.,   1.,   2.],\n",
       "         [  1., 456.,   1.,  ...,   1.,  91.,   1.]],\n",
       "\n",
       "        [[  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
       "         [ 40.,   1.,   5.,  ...,   1.,  20.,  11.],\n",
       "         [ 36.,  28.,  20.,  ...,   1.,  12.,   1.],\n",
       "         ...,\n",
       "         [ 11.,   5.,   1.,  ...,  17.,   6.,   3.],\n",
       "         [163., 389.,  13.,  ...,   1.,  16.,  40.],\n",
       "         [ 38., 123.,   1.,  ...,   1.,  12.,  22.]],\n",
       "\n",
       "        [[  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
       "         [ 46.,   5.,   5.,  ...,   4.,  31.,   4.],\n",
       "         [  1.,   8.,   1.,  ...,   1.,   9.,   1.],\n",
       "         ...,\n",
       "         [  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
       "         [ 55.,   4.,   1.,  ...,   1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.,  ...,   1.,   1.,   1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
       "         [ 10.,   1.,   2.,  ...,   1.,  10.,   1.],\n",
       "         [  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
       "         ...,\n",
       "         [ 18.,   3.,   1.,  ...,   1.,   1.,   1.],\n",
       "         [  5.,   4.,   1.,  ...,   1.,   1.,   1.],\n",
       "         [  1.,  16.,   1.,  ...,   1.,   1.,   1.]],\n",
       "\n",
       "        [[  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
       "         [716.,  46.,  10.,  ...,   3.,   6.,  21.],\n",
       "         [  2.,   2.,   1.,  ...,   1.,   1.,   1.],\n",
       "         ...,\n",
       "         [ 23.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
       "         [  1.,  18.,   1.,  ...,   1.,   1.,   1.],\n",
       "         [  2.,  27.,   1.,  ...,   1.,   1.,   1.]],\n",
       "\n",
       "        [[  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
       "         [ 98.,  14.,  40.,  ...,   3.,  97.,   3.],\n",
       "         [  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
       "         ...,\n",
       "         [  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
       "         [ 34.,  27.,   1.,  ...,   1.,   1.,   1.],\n",
       "         [  4.,  13.,   1.,  ...,   1.,   7.,   1.]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# populate the trigram\n",
    "for key in trigrams:\n",
    "    i0, i1, i2 = stoi[key[0]], stoi[key[1]], stoi[key[2]]\n",
    "    p[i0, i1, i2] = trigrams[key]\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = p / p.sum(dim=2, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7749e-01, 1.4785e-01, 3.6778e-04, 1.5263e-02, 7.2085e-02, 4.1192e-02,\n",
       "        1.1033e-03, 2.0228e-02, 1.6550e-03, 1.2928e-01, 4.0456e-03, 6.4362e-03,\n",
       "        2.5745e-03, 2.2067e-03, 1.5171e-01, 1.8021e-02, 5.5167e-04, 1.8389e-04,\n",
       "        1.4711e-03, 1.8205e-02, 3.2549e-02, 9.1946e-03, 9.0107e-03, 7.3556e-04,\n",
       "        3.6778e-04, 3.2181e-02, 4.0456e-03])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_given_an = P[stoi[\"a\"], stoi['n']]\n",
    "probs_given_an # probability distribution given \"a\" followed by \"n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, '.', tensor(0.2775))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(1)\n",
    "idx = torch.multinomial(probs_given_an, num_samples=1, replacement=True, generator=g)\n",
    "idx.item(), itos[idx.item()], probs_given_an[idx.item()] # 15% chance that \"n\" comes after \"an\", i.e. \"ann\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ma\n",
      "kodan\n",
      "lisonnaelailcia\n",
      "niyannaz\n",
      "velietcgjwpxwbi\n"
     ]
    }
   ],
   "source": [
    "# sampling from the trigram model\n",
    "g = torch.Generator().manual_seed(681236)\n",
    "for i in range(5):\n",
    "    # start at \".\", \".\" -> this is made possible because we increment the count by 1 of all combination of input tuples\n",
    "    i0, i1 = 0, 0\n",
    "    ans = []\n",
    "    while True:\n",
    "        probs = P[i0, i1]\n",
    "        i0 = i1\n",
    "        i1 = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n",
    "        ch = itos[i1]\n",
    "        if ch == \".\":\n",
    "            break\n",
    "        ans.append(ch)\n",
    "\n",
    "    print(\"\".join(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood = 0\n",
    "n = 0\n",
    "for w in words:\n",
    "    w = \".\" + w + \".\"\n",
    "    for ch in zip(w, w[1:], w[2:]):\n",
    "        prob = P[stoi[ch[0]], stoi[ch[1]], stoi[ch[2]]]\n",
    "        log_likelihood += torch.log(prob)\n",
    "        n += 1\n",
    "\n",
    "nll = -log_likelihood / n # averaged negative log likehood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0944)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigram NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . | 0 0\n",
      ". a | 0 1\n",
      ". b | 0 2\n",
      ". c | 0 3\n",
      ". d | 0 4\n",
      ". e | 0 5\n",
      ". f | 0 6\n",
      ". g | 0 7\n",
      ". h | 0 8\n",
      ". i | 0 9\n",
      ". j | 0 10\n",
      ". k | 0 11\n",
      ". l | 0 12\n",
      ". m | 0 13\n",
      ". n | 0 14\n",
      ". o | 0 15\n",
      ". p | 0 16\n",
      ". q | 0 17\n",
      ". r | 0 18\n",
      ". s | 0 19\n",
      ". t | 0 20\n",
      ". u | 0 21\n",
      ". v | 0 22\n",
      ". w | 0 23\n",
      ". x | 0 24\n",
      ". y | 0 25\n",
      ". z | 0 26\n",
      "a . | 1 0\n",
      "a a | 1 1\n",
      "a b | 1 2\n",
      "a c | 1 3\n",
      "a d | 1 4\n",
      "a e | 1 5\n",
      "a f | 1 6\n",
      "a g | 1 7\n",
      "a h | 1 8\n",
      "a i | 1 9\n",
      "a j | 1 10\n",
      "a k | 1 11\n",
      "a l | 1 12\n",
      "a m | 1 13\n",
      "a n | 1 14\n",
      "a o | 1 15\n",
      "a p | 1 16\n",
      "a q | 1 17\n",
      "a r | 1 18\n",
      "a s | 1 19\n",
      "a t | 1 20\n",
      "a u | 1 21\n",
      "a v | 1 22\n",
      "a w | 1 23\n",
      "a x | 1 24\n",
      "a y | 1 25\n",
      "a z | 1 26\n",
      "b . | 2 0\n",
      "b a | 2 1\n",
      "b b | 2 2\n",
      "b c | 2 3\n",
      "b d | 2 4\n",
      "b e | 2 5\n",
      "b f | 2 6\n",
      "b g | 2 7\n",
      "b h | 2 8\n",
      "b i | 2 9\n",
      "b j | 2 10\n",
      "b k | 2 11\n",
      "b l | 2 12\n",
      "b m | 2 13\n",
      "b n | 2 14\n",
      "b o | 2 15\n",
      "b p | 2 16\n",
      "b q | 2 17\n",
      "b r | 2 18\n",
      "b s | 2 19\n",
      "b t | 2 20\n",
      "b u | 2 21\n",
      "b v | 2 22\n",
      "b w | 2 23\n",
      "b x | 2 24\n",
      "b y | 2 25\n",
      "b z | 2 26\n",
      "c . | 3 0\n",
      "c a | 3 1\n",
      "c b | 3 2\n",
      "c c | 3 3\n",
      "c d | 3 4\n",
      "c e | 3 5\n",
      "c f | 3 6\n",
      "c g | 3 7\n",
      "c h | 3 8\n",
      "c i | 3 9\n",
      "c j | 3 10\n",
      "c k | 3 11\n",
      "c l | 3 12\n",
      "c m | 3 13\n",
      "c n | 3 14\n",
      "c o | 3 15\n",
      "c p | 3 16\n",
      "c q | 3 17\n",
      "c r | 3 18\n",
      "c s | 3 19\n",
      "c t | 3 20\n",
      "c u | 3 21\n",
      "c v | 3 22\n",
      "c w | 3 23\n",
      "c x | 3 24\n",
      "c y | 3 25\n",
      "c z | 3 26\n",
      "d . | 4 0\n",
      "d a | 4 1\n",
      "d b | 4 2\n",
      "d c | 4 3\n",
      "d d | 4 4\n",
      "d e | 4 5\n",
      "d f | 4 6\n",
      "d g | 4 7\n",
      "d h | 4 8\n",
      "d i | 4 9\n",
      "d j | 4 10\n",
      "d k | 4 11\n",
      "d l | 4 12\n",
      "d m | 4 13\n",
      "d n | 4 14\n",
      "d o | 4 15\n",
      "d p | 4 16\n",
      "d q | 4 17\n",
      "d r | 4 18\n",
      "d s | 4 19\n",
      "d t | 4 20\n",
      "d u | 4 21\n",
      "d v | 4 22\n",
      "d w | 4 23\n",
      "d x | 4 24\n",
      "d y | 4 25\n",
      "d z | 4 26\n",
      "e . | 5 0\n",
      "e a | 5 1\n",
      "e b | 5 2\n",
      "e c | 5 3\n",
      "e d | 5 4\n",
      "e e | 5 5\n",
      "e f | 5 6\n",
      "e g | 5 7\n",
      "e h | 5 8\n",
      "e i | 5 9\n",
      "e j | 5 10\n",
      "e k | 5 11\n",
      "e l | 5 12\n",
      "e m | 5 13\n",
      "e n | 5 14\n",
      "e o | 5 15\n",
      "e p | 5 16\n",
      "e q | 5 17\n",
      "e r | 5 18\n",
      "e s | 5 19\n",
      "e t | 5 20\n",
      "e u | 5 21\n",
      "e v | 5 22\n",
      "e w | 5 23\n",
      "e x | 5 24\n",
      "e y | 5 25\n",
      "e z | 5 26\n",
      "f . | 6 0\n",
      "f a | 6 1\n",
      "f b | 6 2\n",
      "f c | 6 3\n",
      "f d | 6 4\n",
      "f e | 6 5\n",
      "f f | 6 6\n",
      "f g | 6 7\n",
      "f h | 6 8\n",
      "f i | 6 9\n",
      "f j | 6 10\n",
      "f k | 6 11\n",
      "f l | 6 12\n",
      "f m | 6 13\n",
      "f n | 6 14\n",
      "f o | 6 15\n",
      "f p | 6 16\n",
      "f q | 6 17\n",
      "f r | 6 18\n",
      "f s | 6 19\n",
      "f t | 6 20\n",
      "f u | 6 21\n",
      "f v | 6 22\n",
      "f w | 6 23\n",
      "f x | 6 24\n",
      "f y | 6 25\n",
      "f z | 6 26\n",
      "g . | 7 0\n",
      "g a | 7 1\n",
      "g b | 7 2\n",
      "g c | 7 3\n",
      "g d | 7 4\n",
      "g e | 7 5\n",
      "g f | 7 6\n",
      "g g | 7 7\n",
      "g h | 7 8\n",
      "g i | 7 9\n",
      "g j | 7 10\n",
      "g k | 7 11\n",
      "g l | 7 12\n",
      "g m | 7 13\n",
      "g n | 7 14\n",
      "g o | 7 15\n",
      "g p | 7 16\n",
      "g q | 7 17\n",
      "g r | 7 18\n",
      "g s | 7 19\n",
      "g t | 7 20\n",
      "g u | 7 21\n",
      "g v | 7 22\n",
      "g w | 7 23\n",
      "g x | 7 24\n",
      "g y | 7 25\n",
      "g z | 7 26\n",
      "h . | 8 0\n",
      "h a | 8 1\n",
      "h b | 8 2\n",
      "h c | 8 3\n",
      "h d | 8 4\n",
      "h e | 8 5\n",
      "h f | 8 6\n",
      "h g | 8 7\n",
      "h h | 8 8\n",
      "h i | 8 9\n",
      "h j | 8 10\n",
      "h k | 8 11\n",
      "h l | 8 12\n",
      "h m | 8 13\n",
      "h n | 8 14\n",
      "h o | 8 15\n",
      "h p | 8 16\n",
      "h q | 8 17\n",
      "h r | 8 18\n",
      "h s | 8 19\n",
      "h t | 8 20\n",
      "h u | 8 21\n",
      "h v | 8 22\n",
      "h w | 8 23\n",
      "h x | 8 24\n",
      "h y | 8 25\n",
      "h z | 8 26\n",
      "i . | 9 0\n",
      "i a | 9 1\n",
      "i b | 9 2\n",
      "i c | 9 3\n",
      "i d | 9 4\n",
      "i e | 9 5\n",
      "i f | 9 6\n",
      "i g | 9 7\n",
      "i h | 9 8\n",
      "i i | 9 9\n",
      "i j | 9 10\n",
      "i k | 9 11\n",
      "i l | 9 12\n",
      "i m | 9 13\n",
      "i n | 9 14\n",
      "i o | 9 15\n",
      "i p | 9 16\n",
      "i q | 9 17\n",
      "i r | 9 18\n",
      "i s | 9 19\n",
      "i t | 9 20\n",
      "i u | 9 21\n",
      "i v | 9 22\n",
      "i w | 9 23\n",
      "i x | 9 24\n",
      "i y | 9 25\n",
      "i z | 9 26\n",
      "j . | 10 0\n",
      "j a | 10 1\n",
      "j b | 10 2\n",
      "j c | 10 3\n",
      "j d | 10 4\n",
      "j e | 10 5\n",
      "j f | 10 6\n",
      "j g | 10 7\n",
      "j h | 10 8\n",
      "j i | 10 9\n",
      "j j | 10 10\n",
      "j k | 10 11\n",
      "j l | 10 12\n",
      "j m | 10 13\n",
      "j n | 10 14\n",
      "j o | 10 15\n",
      "j p | 10 16\n",
      "j q | 10 17\n",
      "j r | 10 18\n",
      "j s | 10 19\n",
      "j t | 10 20\n",
      "j u | 10 21\n",
      "j v | 10 22\n",
      "j w | 10 23\n",
      "j x | 10 24\n",
      "j y | 10 25\n",
      "j z | 10 26\n",
      "k . | 11 0\n",
      "k a | 11 1\n",
      "k b | 11 2\n",
      "k c | 11 3\n",
      "k d | 11 4\n",
      "k e | 11 5\n",
      "k f | 11 6\n",
      "k g | 11 7\n",
      "k h | 11 8\n",
      "k i | 11 9\n",
      "k j | 11 10\n",
      "k k | 11 11\n",
      "k l | 11 12\n",
      "k m | 11 13\n",
      "k n | 11 14\n",
      "k o | 11 15\n",
      "k p | 11 16\n",
      "k q | 11 17\n",
      "k r | 11 18\n",
      "k s | 11 19\n",
      "k t | 11 20\n",
      "k u | 11 21\n",
      "k v | 11 22\n",
      "k w | 11 23\n",
      "k x | 11 24\n",
      "k y | 11 25\n",
      "k z | 11 26\n",
      "l . | 12 0\n",
      "l a | 12 1\n",
      "l b | 12 2\n",
      "l c | 12 3\n",
      "l d | 12 4\n",
      "l e | 12 5\n",
      "l f | 12 6\n",
      "l g | 12 7\n",
      "l h | 12 8\n",
      "l i | 12 9\n",
      "l j | 12 10\n",
      "l k | 12 11\n",
      "l l | 12 12\n",
      "l m | 12 13\n",
      "l n | 12 14\n",
      "l o | 12 15\n",
      "l p | 12 16\n",
      "l q | 12 17\n",
      "l r | 12 18\n",
      "l s | 12 19\n",
      "l t | 12 20\n",
      "l u | 12 21\n",
      "l v | 12 22\n",
      "l w | 12 23\n",
      "l x | 12 24\n",
      "l y | 12 25\n",
      "l z | 12 26\n",
      "m . | 13 0\n",
      "m a | 13 1\n",
      "m b | 13 2\n",
      "m c | 13 3\n",
      "m d | 13 4\n",
      "m e | 13 5\n",
      "m f | 13 6\n",
      "m g | 13 7\n",
      "m h | 13 8\n",
      "m i | 13 9\n",
      "m j | 13 10\n",
      "m k | 13 11\n",
      "m l | 13 12\n",
      "m m | 13 13\n",
      "m n | 13 14\n",
      "m o | 13 15\n",
      "m p | 13 16\n",
      "m q | 13 17\n",
      "m r | 13 18\n",
      "m s | 13 19\n",
      "m t | 13 20\n",
      "m u | 13 21\n",
      "m v | 13 22\n",
      "m w | 13 23\n",
      "m x | 13 24\n",
      "m y | 13 25\n",
      "m z | 13 26\n",
      "n . | 14 0\n",
      "n a | 14 1\n",
      "n b | 14 2\n",
      "n c | 14 3\n",
      "n d | 14 4\n",
      "n e | 14 5\n",
      "n f | 14 6\n",
      "n g | 14 7\n",
      "n h | 14 8\n",
      "n i | 14 9\n",
      "n j | 14 10\n",
      "n k | 14 11\n",
      "n l | 14 12\n",
      "n m | 14 13\n",
      "n n | 14 14\n",
      "n o | 14 15\n",
      "n p | 14 16\n",
      "n q | 14 17\n",
      "n r | 14 18\n",
      "n s | 14 19\n",
      "n t | 14 20\n",
      "n u | 14 21\n",
      "n v | 14 22\n",
      "n w | 14 23\n",
      "n x | 14 24\n",
      "n y | 14 25\n",
      "n z | 14 26\n",
      "o . | 15 0\n",
      "o a | 15 1\n",
      "o b | 15 2\n",
      "o c | 15 3\n",
      "o d | 15 4\n",
      "o e | 15 5\n",
      "o f | 15 6\n",
      "o g | 15 7\n",
      "o h | 15 8\n",
      "o i | 15 9\n",
      "o j | 15 10\n",
      "o k | 15 11\n",
      "o l | 15 12\n",
      "o m | 15 13\n",
      "o n | 15 14\n",
      "o o | 15 15\n",
      "o p | 15 16\n",
      "o q | 15 17\n",
      "o r | 15 18\n",
      "o s | 15 19\n",
      "o t | 15 20\n",
      "o u | 15 21\n",
      "o v | 15 22\n",
      "o w | 15 23\n",
      "o x | 15 24\n",
      "o y | 15 25\n",
      "o z | 15 26\n",
      "p . | 16 0\n",
      "p a | 16 1\n",
      "p b | 16 2\n",
      "p c | 16 3\n",
      "p d | 16 4\n",
      "p e | 16 5\n",
      "p f | 16 6\n",
      "p g | 16 7\n",
      "p h | 16 8\n",
      "p i | 16 9\n",
      "p j | 16 10\n",
      "p k | 16 11\n",
      "p l | 16 12\n",
      "p m | 16 13\n",
      "p n | 16 14\n",
      "p o | 16 15\n",
      "p p | 16 16\n",
      "p q | 16 17\n",
      "p r | 16 18\n",
      "p s | 16 19\n",
      "p t | 16 20\n",
      "p u | 16 21\n",
      "p v | 16 22\n",
      "p w | 16 23\n",
      "p x | 16 24\n",
      "p y | 16 25\n",
      "p z | 16 26\n",
      "q . | 17 0\n",
      "q a | 17 1\n",
      "q b | 17 2\n",
      "q c | 17 3\n",
      "q d | 17 4\n",
      "q e | 17 5\n",
      "q f | 17 6\n",
      "q g | 17 7\n",
      "q h | 17 8\n",
      "q i | 17 9\n",
      "q j | 17 10\n",
      "q k | 17 11\n",
      "q l | 17 12\n",
      "q m | 17 13\n",
      "q n | 17 14\n",
      "q o | 17 15\n",
      "q p | 17 16\n",
      "q q | 17 17\n",
      "q r | 17 18\n",
      "q s | 17 19\n",
      "q t | 17 20\n",
      "q u | 17 21\n",
      "q v | 17 22\n",
      "q w | 17 23\n",
      "q x | 17 24\n",
      "q y | 17 25\n",
      "q z | 17 26\n",
      "r . | 18 0\n",
      "r a | 18 1\n",
      "r b | 18 2\n",
      "r c | 18 3\n",
      "r d | 18 4\n",
      "r e | 18 5\n",
      "r f | 18 6\n",
      "r g | 18 7\n",
      "r h | 18 8\n",
      "r i | 18 9\n",
      "r j | 18 10\n",
      "r k | 18 11\n",
      "r l | 18 12\n",
      "r m | 18 13\n",
      "r n | 18 14\n",
      "r o | 18 15\n",
      "r p | 18 16\n",
      "r q | 18 17\n",
      "r r | 18 18\n",
      "r s | 18 19\n",
      "r t | 18 20\n",
      "r u | 18 21\n",
      "r v | 18 22\n",
      "r w | 18 23\n",
      "r x | 18 24\n",
      "r y | 18 25\n",
      "r z | 18 26\n",
      "s . | 19 0\n",
      "s a | 19 1\n",
      "s b | 19 2\n",
      "s c | 19 3\n",
      "s d | 19 4\n",
      "s e | 19 5\n",
      "s f | 19 6\n",
      "s g | 19 7\n",
      "s h | 19 8\n",
      "s i | 19 9\n",
      "s j | 19 10\n",
      "s k | 19 11\n",
      "s l | 19 12\n",
      "s m | 19 13\n",
      "s n | 19 14\n",
      "s o | 19 15\n",
      "s p | 19 16\n",
      "s q | 19 17\n",
      "s r | 19 18\n",
      "s s | 19 19\n",
      "s t | 19 20\n",
      "s u | 19 21\n",
      "s v | 19 22\n",
      "s w | 19 23\n",
      "s x | 19 24\n",
      "s y | 19 25\n",
      "s z | 19 26\n",
      "t . | 20 0\n",
      "t a | 20 1\n",
      "t b | 20 2\n",
      "t c | 20 3\n",
      "t d | 20 4\n",
      "t e | 20 5\n",
      "t f | 20 6\n",
      "t g | 20 7\n",
      "t h | 20 8\n",
      "t i | 20 9\n",
      "t j | 20 10\n",
      "t k | 20 11\n",
      "t l | 20 12\n",
      "t m | 20 13\n",
      "t n | 20 14\n",
      "t o | 20 15\n",
      "t p | 20 16\n",
      "t q | 20 17\n",
      "t r | 20 18\n",
      "t s | 20 19\n",
      "t t | 20 20\n",
      "t u | 20 21\n",
      "t v | 20 22\n",
      "t w | 20 23\n",
      "t x | 20 24\n",
      "t y | 20 25\n",
      "t z | 20 26\n",
      "u . | 21 0\n",
      "u a | 21 1\n",
      "u b | 21 2\n",
      "u c | 21 3\n",
      "u d | 21 4\n",
      "u e | 21 5\n",
      "u f | 21 6\n",
      "u g | 21 7\n",
      "u h | 21 8\n",
      "u i | 21 9\n",
      "u j | 21 10\n",
      "u k | 21 11\n",
      "u l | 21 12\n",
      "u m | 21 13\n",
      "u n | 21 14\n",
      "u o | 21 15\n",
      "u p | 21 16\n",
      "u q | 21 17\n",
      "u r | 21 18\n",
      "u s | 21 19\n",
      "u t | 21 20\n",
      "u u | 21 21\n",
      "u v | 21 22\n",
      "u w | 21 23\n",
      "u x | 21 24\n",
      "u y | 21 25\n",
      "u z | 21 26\n",
      "v . | 22 0\n",
      "v a | 22 1\n",
      "v b | 22 2\n",
      "v c | 22 3\n",
      "v d | 22 4\n",
      "v e | 22 5\n",
      "v f | 22 6\n",
      "v g | 22 7\n",
      "v h | 22 8\n",
      "v i | 22 9\n",
      "v j | 22 10\n",
      "v k | 22 11\n",
      "v l | 22 12\n",
      "v m | 22 13\n",
      "v n | 22 14\n",
      "v o | 22 15\n",
      "v p | 22 16\n",
      "v q | 22 17\n",
      "v r | 22 18\n",
      "v s | 22 19\n",
      "v t | 22 20\n",
      "v u | 22 21\n",
      "v v | 22 22\n",
      "v w | 22 23\n",
      "v x | 22 24\n",
      "v y | 22 25\n",
      "v z | 22 26\n",
      "w . | 23 0\n",
      "w a | 23 1\n",
      "w b | 23 2\n",
      "w c | 23 3\n",
      "w d | 23 4\n",
      "w e | 23 5\n",
      "w f | 23 6\n",
      "w g | 23 7\n",
      "w h | 23 8\n",
      "w i | 23 9\n",
      "w j | 23 10\n",
      "w k | 23 11\n",
      "w l | 23 12\n",
      "w m | 23 13\n",
      "w n | 23 14\n",
      "w o | 23 15\n",
      "w p | 23 16\n",
      "w q | 23 17\n",
      "w r | 23 18\n",
      "w s | 23 19\n",
      "w t | 23 20\n",
      "w u | 23 21\n",
      "w v | 23 22\n",
      "w w | 23 23\n",
      "w x | 23 24\n",
      "w y | 23 25\n",
      "w z | 23 26\n",
      "x . | 24 0\n",
      "x a | 24 1\n",
      "x b | 24 2\n",
      "x c | 24 3\n",
      "x d | 24 4\n",
      "x e | 24 5\n",
      "x f | 24 6\n",
      "x g | 24 7\n",
      "x h | 24 8\n",
      "x i | 24 9\n",
      "x j | 24 10\n",
      "x k | 24 11\n",
      "x l | 24 12\n",
      "x m | 24 13\n",
      "x n | 24 14\n",
      "x o | 24 15\n",
      "x p | 24 16\n",
      "x q | 24 17\n",
      "x r | 24 18\n",
      "x s | 24 19\n",
      "x t | 24 20\n",
      "x u | 24 21\n",
      "x v | 24 22\n",
      "x w | 24 23\n",
      "x x | 24 24\n",
      "x y | 24 25\n",
      "x z | 24 26\n",
      "y . | 25 0\n",
      "y a | 25 1\n",
      "y b | 25 2\n",
      "y c | 25 3\n",
      "y d | 25 4\n",
      "y e | 25 5\n",
      "y f | 25 6\n",
      "y g | 25 7\n",
      "y h | 25 8\n",
      "y i | 25 9\n",
      "y j | 25 10\n",
      "y k | 25 11\n",
      "y l | 25 12\n",
      "y m | 25 13\n",
      "y n | 25 14\n",
      "y o | 25 15\n",
      "y p | 25 16\n",
      "y q | 25 17\n",
      "y r | 25 18\n",
      "y s | 25 19\n",
      "y t | 25 20\n",
      "y u | 25 21\n",
      "y v | 25 22\n",
      "y w | 25 23\n",
      "y x | 25 24\n",
      "y y | 25 25\n",
      "y z | 25 26\n",
      "z . | 26 0\n",
      "z a | 26 1\n",
      "z b | 26 2\n",
      "z c | 26 3\n",
      "z d | 26 4\n",
      "z e | 26 5\n",
      "z f | 26 6\n",
      "z g | 26 7\n",
      "z h | 26 8\n",
      "z i | 26 9\n",
      "z j | 26 10\n",
      "z k | 26 11\n",
      "z l | 26 12\n",
      "z m | 26 13\n",
      "z n | 26 14\n",
      "z o | 26 15\n",
      "z p | 26 16\n",
      "z q | 26 17\n",
      "z r | 26 18\n",
      "z s | 26 19\n",
      "z t | 26 20\n",
      "z u | 26 21\n",
      "z v | 26 22\n",
      "z w | 26 23\n",
      "z x | 26 24\n",
      "z y | 26 25\n",
      "z z | 26 26\n"
     ]
    }
   ],
   "source": [
    "# encodes all possible permutations of two consecutive characters, e.g. [.a .b .c ... aa ab ac ... za zb zc ... zz]\n",
    "i = 0\n",
    "enc = {}\n",
    "for ch1 in chars:\n",
    "    for ch2 in chars:\n",
    "        print(ch1, ch2, \"|\", stoi[ch1], stoi[ch2])\n",
    "        enc[(stoi[ch1], stoi[ch2])] = i\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(728, 729)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 26, 26 corresponds to zz\n",
    "enc[(26, 26)], len(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training data\n",
    "xs, ys = [], []\n",
    "for w in words:\n",
    "    w = \".\" + w + \".\"\n",
    "    for ch in zip(w, w[1:], w[2:]):\n",
    "        x = (stoi[ch[0]], stoi[ch[1]])\n",
    "        y = stoi[ch[2]]\n",
    "\n",
    "        # use the encoding for x to generate 729 (27^2) unique indexes (each representing a unique permutation of two characters)\n",
    "        xs.append(enc[x])\n",
    "        ys.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([5, 148, 364, 352, 15, 417, 333, 265, 603, 244],\n",
       " [13, 13, 1, 0, 12, 9, 22, 9, 1, 0])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:10], ys[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196113, 196113)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xs), len(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0318, 0.0544, 0.0488,  ..., 0.0359, 0.0234, 0.0115],\n",
       "        [0.0958, 0.0978, 0.0305,  ..., 0.0198, 0.0120, 0.0403],\n",
       "        [0.0126, 0.0046, 0.0515,  ..., 0.0097, 0.0062, 0.0198],\n",
       "        ...,\n",
       "        [0.0936, 0.0121, 0.0714,  ..., 0.0120, 0.0382, 0.0205],\n",
       "        [0.0209, 0.0107, 0.0017,  ..., 0.1180, 0.0145, 0.0256],\n",
       "        [0.0818, 0.0179, 0.0247,  ..., 0.0314, 0.0452, 0.0202]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.randn(27 * 27, 27).float()\n",
    "\n",
    "one_hot_enc = F.one_hot(xs, num_classes=len(enc)).float() # (196113, 729)\n",
    "logits = one_hot_enc @ W                          # (196113, 27)\n",
    "counts = logits.exp() \n",
    "probs = counts / counts.sum(1, keepdim=True)\n",
    "probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([27]), 196113, tensor(1.))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0].shape, len(probs), probs[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7848)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll = -probs[torch.arange(len(xs)), ys].log().mean()\n",
    "nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(123)\n",
    "W = torch.randn(27 * 27, 27, requires_grad=True, generator=g).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.738034248352051\n",
      "3.722470998764038\n",
      "3.7070956230163574\n",
      "3.691904067993164\n",
      "3.6768932342529297\n",
      "3.6620590686798096\n",
      "3.647399663925171\n",
      "3.6329126358032227\n",
      "3.618595838546753\n",
      "3.6044468879699707\n",
      "3.5904648303985596\n",
      "3.576647996902466\n",
      "3.5629961490631104\n",
      "3.5495083332061768\n",
      "3.5361838340759277\n",
      "3.523022174835205\n",
      "3.510023593902588\n",
      "3.497187614440918\n",
      "3.4845142364501953\n",
      "3.472003936767578\n",
      "3.4596571922302246\n",
      "3.4474737644195557\n",
      "3.4354536533355713\n",
      "3.423597574234009\n",
      "3.411905288696289\n",
      "3.400377035140991\n",
      "3.3890130519866943\n",
      "3.377812147140503\n",
      "3.3667750358581543\n",
      "3.3559012413024902\n",
      "3.3451900482177734\n",
      "3.3346402645111084\n",
      "3.324252128601074\n",
      "3.314023017883301\n",
      "3.303952932357788\n",
      "3.2940409183502197\n",
      "3.2842843532562256\n",
      "3.274681806564331\n",
      "3.2652313709259033\n",
      "3.255932092666626\n",
      "3.246781826019287\n",
      "3.2377774715423584\n",
      "3.2289178371429443\n",
      "3.220200538635254\n",
      "3.211623191833496\n",
      "3.203183174133301\n",
      "3.1948790550231934\n",
      "3.1867077350616455\n",
      "3.178666830062866\n",
      "3.1707541942596436\n",
      "3.1629679203033447\n",
      "3.1553046703338623\n",
      "3.1477630138397217\n",
      "3.1403400897979736\n",
      "3.1330337524414062\n",
      "3.125842332839966\n",
      "3.118762731552124\n",
      "3.111793279647827\n",
      "3.1049318313598633\n",
      "3.0981762409210205\n",
      "3.091524124145508\n",
      "3.0849740505218506\n",
      "3.078523635864258\n",
      "3.0721709728240967\n",
      "3.0659143924713135\n",
      "3.0597519874572754\n",
      "3.0536813735961914\n",
      "3.047701358795166\n",
      "3.0418105125427246\n",
      "3.036005973815918\n",
      "3.0302867889404297\n",
      "3.024651050567627\n",
      "3.019097328186035\n",
      "3.0136234760284424\n",
      "3.0082287788391113\n",
      "3.002910852432251\n",
      "2.997668504714966\n",
      "2.992500066757202\n",
      "2.987405300140381\n",
      "2.9823801517486572\n",
      "2.9774255752563477\n",
      "2.972539186477661\n",
      "2.967719554901123\n",
      "2.962965488433838\n",
      "2.9582760334014893\n",
      "2.9536492824554443\n",
      "2.9490838050842285\n",
      "2.9445793628692627\n",
      "2.940133571624756\n",
      "2.9357454776763916\n",
      "2.931414842605591\n",
      "2.9271395206451416\n",
      "2.9229187965393066\n",
      "2.9187512397766113\n",
      "2.9146358966827393\n",
      "2.910572052001953\n",
      "2.906558036804199\n",
      "2.9025933742523193\n",
      "2.898676633834839\n",
      "2.8948075771331787\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "for _ in range(100):\n",
    "    xenc = F.one_hot(xs, num_classes=len(enc)).float()\n",
    "    logits = xenc @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdim=True)\n",
    "    loss = -probs[torch.arange(xs.nelement()), ys].log().mean() \n",
    "    print(loss.item())\n",
    "\n",
    "    # backpass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update params\n",
    "    W.data += -10 * W.grad\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-cv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
